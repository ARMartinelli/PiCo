PiCo
===============

PiCo stands for **Pi**peline **Co**mposition.

The main entity in PiCo is the *Pipeline*, basically a DAG-composition of processing elements. 

This model is intended to give the user an unique interface for both stream and batch processing, hiding completely data management and focusing only on operations, which are represented by Pipeline stages. 

The DSL we propose is entirely implemented in C++11, exploiting the FastFlow library as runtime.

## How to compile
To build any PiCo application, the FastFlow library should be provided.
PiCo comes with a built-in version of FastFlow. If the least one is needed, it can be downloaded from the [SourceForge repository](https://sourceforge.net/projects/mc-fastflow/), or just type

`$ svn checkout svn://svn.code.sf.net/p/mc-fastflow/code/ mc-fastflow-code`

and then add a symbolic link to the FastFlow library into the PiCo directory:

`$ ln -s /path/to/FastFlow/ff /PiCo/root/dir`

In `test` directory two example are present: a word count (`pico_wc.cpp`) and a merging pipelines (`pico_merge.cpp`).
To compile those tests:

`$ cd test`

`$ make`

This command will also launch the two examples: two OK messages confirm the correctness of the results.

To run each single example, just type:

`$ ./pico_merge -i <input file> -o <output file> [-w workers] [-b batch-size]`

or

`$ ./pico_wc -i <input file> -o <output file> [-w workers] [-b batch-size]`

Test input files can be found in `test/testdata/`.

In the `example` directory can be found an optimized word count, a stock-market and a fold+reduce benchmarks.
The word count example can be executed as the following:

`$ cd word-count`

`$ make`

`$ ./pico_wc -i <input file> -o <output file> [-w workers] [-b batch-size]`

and the input data can be generated with the application in the `word-count/testdata` directory. 
Input text is generated by utilizing an english dictionary `dictionary.txt`.
An input text can be generated as follows:

`$ cd testdata `

`$ make`

`$ ./generate_text <dictionary file> <n. of lines> >> <output.file>`

The fold+reduce example is a basic usage of the fold+reduce operator with state. 
This example will read a list of integers and outputs a list of lists containing all the occurrences of integers in input.
Each entry of the input file is first converted into a <string, int> pair, where the key represents the current number parsed as a string.
Such keys are stored as a local state in a map of pairs <string, vector<int>> (**fold** stage) and merged into a global map (**reduce** stage).

`$ cd foldreduce `

`$ make`

`$ ./pico_foldred -i <input file> -o <output file> [-w workers] [-b batch-size] `

An example input file can be found in `data/input`

### Graph Visualization
Each example produces a `.dot` file for a graphical representation of the application pipeline coded in Graphviz.
To visualize these graphs, use the command:

`dot -Tpng filename.dot -o outfile.png`
